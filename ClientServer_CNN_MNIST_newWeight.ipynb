{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClientServer_CNN_MNIST_newWeight.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0vX9HCXxLqC"
      },
      "source": [
        "Setup model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHaomBqoxJTE"
      },
      "source": [
        "# baseline cnn model for mnist\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np\n",
        "import timeit\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.01, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# load dataset\n",
        "trainX, trainY, test_X, test_Y = load_dataset()\n",
        "# prepare pixel data\n",
        "trainX, testX = prep_pixels(trainX, test_X)\n",
        "# evaluate model\n",
        "test_X, valX, test_Y, valY = train_test_split(test_X, test_Y, test_size=0.5)\n",
        "trainX, trainX1, trainY, trainY1 = train_test_split(trainX, trainY, test_size=0.3)\n",
        "trainX, trainX2, trainY, trainY2 = train_test_split(trainX, trainY, test_size=0.4)\n",
        "trainX, trainX3, trainY, trainY3 = train_test_split(trainX, trainY, test_size=0.5)\n",
        "trainX1, trainX4, trainY1, trainY4 = train_test_split(trainX1, trainY1, test_size=0.35)\n",
        "trainX1, trainX5, trainY1, trainY5 = train_test_split(trainX1, trainY1, test_size=0.25)\n",
        "trainX2, trainX6, trainY2, trainY6 = train_test_split(trainX2, trainY2, test_size=0.45)\n",
        "trainX4, trainX7, trainY4, trainY7 = train_test_split(trainX4, trainY4, test_size=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6EQgfqFqFlE"
      },
      "source": [
        "Check shape of input dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7xgj_vGgawN",
        "outputId": "c08045a7-8886-47a0-9d75-91ad0bc47fd4"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainX1.shape)\n",
        "print(trainX2.shape)\n",
        "print(trainX3.shape)\n",
        "print(trainX4.shape)\n",
        "print(trainX5.shape)\n",
        "print(trainX6.shape)\n",
        "print(trainX7.shape)\n",
        "print(valX.shape)\n",
        "print(test_X.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12600, 28, 28, 1)\n",
            "(8775, 28, 28, 1)\n",
            "(9240, 28, 28, 1)\n",
            "(12600, 28, 28, 1)\n",
            "(5040, 28, 28, 1)\n",
            "(2925, 28, 28, 1)\n",
            "(7560, 28, 28, 1)\n",
            "(1260, 28, 28, 1)\n",
            "(5000, 28, 28, 1)\n",
            "(5000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHStyegMNFFy"
      },
      "source": [
        "Step 1: \n",
        "    for 1/10 dataset train for server (sv)\n",
        "    for 1/10 dataset train for client 1 (c1)\n",
        "    for 1/10 dataset train for client 2 (c2)\n",
        "    for 1/10 dataset train for client 3 (c3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlS-zCgh-EKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3599f5-208c-4438-fdbd-c8e7bf17d64a"
      },
      "source": [
        "c1 = define_model()\n",
        "c2 = define_model()\n",
        "c3 = define_model()\n",
        "sv = define_model()\n",
        "\n",
        "start = timeit.default_timer()\n",
        "sv.fit(trainX, trainY, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('Server: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c1.fit(trainX1, trainY1, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C1: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c2.fit(trainX2, trainY2, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C2: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c3.fit(trainX3, trainY3, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C3: {}'.format(end-start))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Server: 5.510091069999817\n",
            "C1: 4.6703149559998565\n",
            "C2: 4.729469571999971\n",
            "C3: 5.79371364099984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-PNQFLkNmFD"
      },
      "source": [
        "Test Step 1: Test model in server and clients (c1, c2, c3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r38KhdGcgsnD",
        "outputId": "2b98d370-e8bb-405e-c29d-1e348800917c"
      },
      "source": [
        "\n",
        "print(\"==============train result=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C1: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c2.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C2: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c3.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C3: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============train result=============\n",
            "Server:  0.9656\n",
            "C1:  0.9554\n",
            "C2:  0.9644\n",
            "C3:  0.965\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SHoaLz9OKRD"
      },
      "source": [
        "Step 2: update weight_avg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IliZG0RTSdTL",
        "outputId": "0064a139-87b1-401c-8e1d-1d3f1535840f"
      },
      "source": [
        "avg = (trainX.shape[0]*np.array(sv.get_weights())+trainX1.shape[0]*np.array(c1.get_weights()) + trainX2.shape[0]*np.array(c2.get_weights()) + trainX3.shape[0]*np.array(c3.get_weights())) / (trainX.shape[0]+trainX1.shape[0]+trainX2.shape[0]+trainX3.shape[0])\n",
        "c1.set_weights(avg)\n",
        "c2.set_weights(avg)\n",
        "c3.set_weights(avg)\n",
        "sv.set_weights(avg)\n",
        "print(\"==============Result with weight_Avg=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Client 1 (c1): ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==============Result with weight_Avg=============\n",
            "Server:  0.361\n",
            "Client 1 (c1):  0.361\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqM-YblUN9OS"
      },
      "source": [
        "Step 3: train client 1 and client 2 with new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0amqONBTccC",
        "outputId": "4fa7560d-af44-47d2-9445-731758efc926"
      },
      "source": [
        "start = timeit.default_timer()\n",
        "c1.fit(trainX4, trainY4, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C1: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c2.fit(trainX5, trainY5, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C2: {}'.format(end-start))\n",
        "\n",
        "print(\"==============train result=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C1: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c2.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C2: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c3.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C3: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C1: 5.150707537000017\n",
            "C2: 2.358487829000069\n",
            "==============train result=============\n",
            "Server:  0.361\n",
            "C1:  0.943\n",
            "C2:  0.9322\n",
            "C3:  0.361\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ijfwxVXO0iI"
      },
      "source": [
        "Step 4: update weight_avg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSIm6rBRYKDB",
        "outputId": "c7552f47-2ab5-40eb-b27f-f5f4c32322ab"
      },
      "source": [
        "\n",
        "avg = (0*np.array(sv.get_weights())+trainX4.shape[0]*np.array(c1.get_weights()) + trainX5.shape[0]*np.array(c2.get_weights()) + 0*np.array(c3.get_weights())) / (trainX4.shape[0]+trainX5.shape[0])\n",
        "\n",
        "c1.set_weights(avg)\n",
        "c2.set_weights(avg)\n",
        "c3.set_weights(avg)\n",
        "sv.set_weights(avg)\n",
        "print(\"==============Result Avg=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Client 1: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==============Result Avg=============\n",
            "Server:  0.9412\n",
            "Client 1:  0.9412\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPdYsF4vPFQC"
      },
      "source": [
        "Step 5: Next, train client 1 and client 2, no train server and client 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hQZVezQUGu5",
        "outputId": "64a1f8d4-1e4c-4423-f95d-9703f5ab79d3"
      },
      "source": [
        "start = timeit.default_timer()\n",
        "c1.fit(trainX6, trainY6, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C1: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c2.fit(trainX7, trainY7, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C2: {}'.format(end-start))\n",
        "\n",
        "print(\"==============Result train=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C1: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c2.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C2: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c3.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C3: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C1: 3.4224594740001066\n",
            "C2: 2.065816864999988\n",
            "==============Result train=============\n",
            "Server:  0.9412\n",
            "C1:  0.962\n",
            "C2:  0.9394\n",
            "C3:  0.9412\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12-B7Dh0PqKP"
      },
      "source": [
        "Step 5_3: update weight for all computer and check result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW0nbJyZmXOC",
        "outputId": "9ae1cd79-5e38-4e9c-ad94-a0ba98ae5157"
      },
      "source": [
        "avg = (0*np.array(sv.get_weights())+trainX6.shape[0]*np.array(c1.get_weights()) + trainX7.shape[0]*np.array(c2.get_weights()) + 0*np.array(c3.get_weights())) / (trainX6.shape[0]+trainX7.shape[0])\n",
        "\n",
        "c1.set_weights(avg)\n",
        "c2.set_weights(avg)\n",
        "c3.set_weights(avg)\n",
        "sv.set_weights(avg)\n",
        "print(\"==============result Avg=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Client 1: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==============result Avg=============\n",
            "Server:  0.9608\n",
            "Client 1:  0.9608\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxiI-1WDQHHD"
      },
      "source": [
        "Step 6: Reuslt when train one computer which full dataset train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvizyRwRphu9",
        "outputId": "fd5e576b-164f-4ab5-b2cf-a465a10dc3b7"
      },
      "source": [
        "x = np.concatenate((trainX, trainX1, trainX2, trainX3, trainX4, trainX5, trainX6, trainX7), axis=0)\n",
        "y = np.concatenate((trainY, trainY1, trainY2, trainY3, trainY4, trainY5, trainY6, trainY7), axis=0)\n",
        "start = timeit.default_timer()\n",
        "model = define_model()\n",
        "model.fit(x, y, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "print(\"==============Result with one computer=============\")\n",
        "y_pred = model.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Result: ', accuracy_score(y_pred1, y_pred))\n",
        "end = timeit.default_timer()\n",
        "print('time train full: {}'.format(end-start))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==============Result with one computer=============\n",
            "Result:  0.9786\n",
            "time train full: 16.70515230900014\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}