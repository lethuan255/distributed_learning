{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClientServer_CNN_MNIST_AvgWeight.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0vX9HCXxLqC"
      },
      "source": [
        "Setup model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHaomBqoxJTE",
        "outputId": "9536ecfa-0e07-43fb-c311-21eaa39beca8"
      },
      "source": [
        "# baseline cnn model for mnist\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np\n",
        "import timeit\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.01, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# load dataset\n",
        "trainX, trainY, test_X, test_Y = load_dataset()\n",
        "# prepare pixel data\n",
        "trainX, testX = prep_pixels(trainX, test_X)\n",
        "# evaluate model\n",
        "test_X, valX, test_Y, valY = train_test_split(test_X, test_Y, test_size=0.5)\n",
        "trainX, trainX1, trainY, trainY1 = train_test_split(trainX, trainY, test_size=0.3)\n",
        "trainX, trainX2, trainY, trainY2 = train_test_split(trainX, trainY, test_size=0.4)\n",
        "trainX, trainX3, trainY, trainY3 = train_test_split(trainX, trainY, test_size=0.5)\n",
        "trainX1, trainX4, trainY1, trainY4 = train_test_split(trainX1, trainY1, test_size=0.35)\n",
        "trainX1, trainX5, trainY1, trainY5 = train_test_split(trainX1, trainY1, test_size=0.25)\n",
        "trainX2, trainX6, trainY2, trainY6 = train_test_split(trainX2, trainY2, test_size=0.45)\n",
        "trainX4, trainX7, trainY4, trainY7 = train_test_split(trainX4, trainY4, test_size=0.2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6EQgfqFqFlE"
      },
      "source": [
        "Check shape of input dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7xgj_vGgawN",
        "outputId": "90dededd-3713-4a2a-d6c3-21e53f6125ba"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainX1.shape)\n",
        "print(trainX2.shape)\n",
        "print(trainX3.shape)\n",
        "print(trainX4.shape)\n",
        "print(trainX5.shape)\n",
        "print(trainX6.shape)\n",
        "print(trainX7.shape)\n",
        "print(valX.shape)\n",
        "print(test_X.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12600, 28, 28, 1)\n",
            "(8775, 28, 28, 1)\n",
            "(9240, 28, 28, 1)\n",
            "(12600, 28, 28, 1)\n",
            "(5040, 28, 28, 1)\n",
            "(2925, 28, 28, 1)\n",
            "(7560, 28, 28, 1)\n",
            "(1260, 28, 28, 1)\n",
            "(5000, 28, 28, 1)\n",
            "(5000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHStyegMNFFy"
      },
      "source": [
        "Step 1: \n",
        "    for 1/10 dataset train for server (sv)\n",
        "    for 1/10 dataset train for client 1 (c1)\n",
        "    for 1/10 dataset train for client 2 (c2)\n",
        "    for 1/10 dataset train for client 3 (c3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlS-zCgh-EKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69d4d8c-2e45-4daf-8e58-d74f2a37eecc"
      },
      "source": [
        "c1 = define_model()\n",
        "c2 = define_model()\n",
        "c3 = define_model()\n",
        "sv = define_model()\n",
        "\n",
        "start = timeit.default_timer()\n",
        "sv.fit(trainX, trainY, epochs=10, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('Server: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c1.fit(trainX1, trainY1, epochs=10, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C1: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c2.fit(trainX2, trainY2, epochs=10, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C2: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c3.fit(trainX3, trainY3, epochs=10, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C3: {}'.format(end-start))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Server: 30.082124149000038\n",
            "C1: 3.1138961869999093\n",
            "C2: 1.9538572849999127\n",
            "C3: 3.094304616999807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-PNQFLkNmFD"
      },
      "source": [
        "Test Step 1: Test model in server and clients (c1, c2, c3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r38KhdGcgsnD",
        "outputId": "3ab0b4cb-cb4c-4c7a-e116-68875c5ef915"
      },
      "source": [
        "\n",
        "print(\"==============train result=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C1: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c2.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C2: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c3.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C3: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============train result=============\n",
            "Server:  0.9526\n",
            "C1:  0.9404\n",
            "C2:  0.9436\n",
            "C3:  0.9498\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SHoaLz9OKRD"
      },
      "source": [
        "Step 2: update weight_avg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IliZG0RTSdTL",
        "outputId": "1bc1ee13-9199-4280-d809-dc9e88bca552"
      },
      "source": [
        "avg = (np.array(c1.get_weights()) + np.array(c2.get_weights()) + np.array(c3.get_weights()) + np.array(sv.get_weights())) / 4\n",
        "c1.set_weights(avg)\n",
        "c2.set_weights(avg)\n",
        "c3.set_weights(avg)\n",
        "sv.set_weights(avg)\n",
        "print(\"==============Result with weight_Avg=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Client 1 (c1): ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==============Result with weight_Avg=============\n",
            "Server:  0.711\n",
            "Client 1 (c1):  0.711\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqM-YblUN9OS"
      },
      "source": [
        "Step 3: train client 1 and client 2 with new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0amqONBTccC",
        "outputId": "6759a07f-d8e0-424f-ac47-5d31bef87aca"
      },
      "source": [
        "start = timeit.default_timer()\n",
        "c1.fit(trainX4, trainY4, epochs=10, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C1: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c2.fit(trainX5, trainY5, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C2: {}'.format(end-start))\n",
        "\n",
        "print(\"==============train result=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C1: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c2.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C2: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c3.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C3: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C1: 0.9264401730001737\n",
            "C2: 2.296632405999844\n",
            "==============train result=============\n",
            "Server:  0.711\n",
            "C1:  0.917\n",
            "C2:  0.925\n",
            "C3:  0.711\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ijfwxVXO0iI"
      },
      "source": [
        "Step 4: update weight_avg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSIm6rBRYKDB",
        "outputId": "75c40308-417b-41d7-f24f-652dee6e05af"
      },
      "source": [
        "avg = (np.array(c1.get_weights()) + np.array(c2.get_weights()) + np.array(c3.get_weights()) + np.array(sv.get_weights())) / 4\n",
        "c1.set_weights(avg)\n",
        "c2.set_weights(avg)\n",
        "c3.set_weights(avg)\n",
        "sv.set_weights(avg)\n",
        "print(\"==============Result Avg=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Client 1: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==============Result Avg=============\n",
            "Server:  0.917\n",
            "Client 1:  0.917\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPdYsF4vPFQC"
      },
      "source": [
        "Step 5: Next, train client 1 and client 2, no train server and client 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hQZVezQUGu5",
        "outputId": "0b59e288-e2c6-41f7-c47b-5d3c946e87da"
      },
      "source": [
        "start = timeit.default_timer()\n",
        "c1.fit(trainX6, trainY6, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C1: {}'.format(end-start))\n",
        "\n",
        "start = timeit.default_timer()\n",
        "c2.fit(trainX7, trainY7, epochs=10, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "end = timeit.default_timer()\n",
        "print('C2: {}'.format(end-start))\n",
        "\n",
        "print(\"==============Result train=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C1: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c2.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C2: ', accuracy_score(y_pred1, y_pred))\n",
        "\n",
        "y_pred = c3.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('C3: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C1: 3.330065909000041\n",
            "C2: 0.6683926630000769\n",
            "==============Result train=============\n",
            "Server:  0.917\n",
            "C1:  0.9538\n",
            "C2:  0.9156\n",
            "C3:  0.917\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12-B7Dh0PqKP"
      },
      "source": [
        "Step 5_3: update weight for all computer and check result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW0nbJyZmXOC",
        "outputId": "78dceccf-9243-494a-8a41-c7e8a84807d5"
      },
      "source": [
        "avg = (np.array(c1.get_weights()) + np.array(c2.get_weights()) + np.array(c3.get_weights()) + np.array(sv.get_weights())) / 4\n",
        "c1.set_weights(avg)\n",
        "c2.set_weights(avg)\n",
        "c3.set_weights(avg)\n",
        "sv.set_weights(avg)\n",
        "print(\"==============result Avg=============\")\n",
        "y_pred = sv.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Server: ', accuracy_score(y_pred1, y_pred))\n",
        "y_pred = c1.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Client 1: ', accuracy_score(y_pred1, y_pred))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==============result Avg=============\n",
            "Server:  0.9354\n",
            "Client 1:  0.9354\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxiI-1WDQHHD"
      },
      "source": [
        "Step 6: Reuslt when train one computer which full dataset train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvizyRwRphu9",
        "outputId": "edee3c3a-215d-4254-b9bf-c01bac3199a8"
      },
      "source": [
        "x = np.concatenate((trainX, trainX1, trainX2, trainX3, trainX4, trainX5, trainX6, trainX7), axis=0)\n",
        "y = np.concatenate((trainY, trainY1, trainY2, trainY3, trainY4, trainY5, trainY6, trainY7), axis=0)\n",
        "start = timeit.default_timer()\n",
        "model = define_model()\n",
        "model.fit(x, y, epochs=30, batch_size=512, validation_data=(valX, valY), verbose=0)\n",
        "print(\"==============Result with one computer=============\")\n",
        "y_pred = model.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "y_pred1 = np.argmax(test_Y, axis=-1)\n",
        "print('Result: ', accuracy_score(y_pred1, y_pred))\n",
        "end = timeit.default_timer()\n",
        "print('time train full: {}'.format(end-start))\n",
        "print(\"========================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==============Result with one computer=============\n",
            "Result:  0.9792\n",
            "time train full: 21.372641905000137\n",
            "========================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}